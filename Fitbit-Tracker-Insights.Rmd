---
title: "Fitbit-Tracker-Insights"
author: "Mithil Guru"
date: '2022-06-26'
output: html_document
---

# FITBIT TRACKER INSIGHTS

## INTRO

Fitbit is a fitness technology company that produces wearables to monitor various aspects of health and activity, such as heart rate, daily steps, sleep-quality, etc. There is a tremendous amount of data collected by these wearable devices daily that can be harnessed to benefit the consumer and the company. I will explore the Fitbit fitness tracker data Kaggle dataset (https://www.kaggle.com/arashnic/fitbit) for business insight as an extension of the Google Data Analytics Certificate Capstone Project. 

**OBJECTIVES**

1. Discover trends in usage

2. Generate recommendations for product strategy



## METHODS

Checking the data first for validity and integrity. 
The data description indicates it is generated from respondents to a survey in 2016. It includes consented data from the personal trackers thirty users.

**DATA - Assessment**

Assessing the source of the data, it is likely not reliable as the sample size is only 30, the survey was conducted and compiled by a third-party organization, and the data may be slighlty inconsistent, due to the source including data from different trackers, and outdated as current trackers have improved capabilities. Additionally, there is a possibility of voluntary response bias due to the participants consenting to take place in the study, which may have influenced their habits during the course of the study. There is also no extra information provided about the participants, so the sample may not be truly representative of the general population.

Despite the limitations, the dataset is chosen for analysis since it is one of the few publicly available sources with Fitbit tracker data - most tracker data is locked for user privacy. The only alternative for reliable data would be to self-analyze Fitbit data with the use of the Fitbit API, but this limits study to one subject. 

**DATA - Summary**

The data includes 18 total datasets (CSV files) representing data collected by the trackers. A quick search through the files revealed that most of the data was collected and compiled in the dailyActivity.csv dataset, and the remaining files contain specific intervals or variations of the quantitative data. 

The datasets can be categorized as such - 

**Activity** - 

- dailyActivity

- dailySteps, hourlySteps, minuteSteps (Narrow & Wide)

- dailyIntensities, hourlyIntensities, minuteIntensities (Narrow & Wide)

**Sleep** - 

- sleepDay, minuteSleep

**Calories / Weight** - 

- dailyCalories, hourlyCalories, minuteCalories (Narrow & Wide)

- weightLogInfo

**Other** - 

- heartrate

- minuteMETs (Energy Expenditure)


Most of the data is explained in the dailyActivity file, and the sleepDay file provides additional information for analysis. The hourlySteps and hourlyIntensities datasets also supplement the daily activity data. The remaining datasets can be condensed. 

The weightLog, heartrate, and minuteSleep files do not contain data for all the subjects, and will not be considered as they do not meet minimum sample size requirements. The minuteMETs file does not provide relevant data for the business objective.

**DATA - Features** 
All variables are quantitative.

**Steps** - total steps per day

**Intensity** - sorted by level (Sedentary, Lightly Active, Moderately Active, Very Active) for distance and time

**Calories** - total calories burned per day

**Sleep** - total sleep sessions per day, minutes asleep, time in bed

The initial chosen datasets.
```{r}
# imports
library(tidyverse)

# data
df <- read_csv('Fitbit-Data/dailyActivity_merged.csv')
dfs <- read_csv('Fitbit-Data/sleepDay_merged.csv')

dfhs <- read_csv('Fitbit-Data/hourlySteps_merged.csv')
dfhi <- read_csv('Fitbit-Data/hourlyIntensities_merged.csv')

head(df)
head(dfs)
head(dfhs)
head(dfhi)
```
Using SQL (BigQuery database) to perform the initial data preparation and R (dplyr) for additional data transformation and visualizations.



## FEATURE ENGINEERING

Transforming hourly activity data.
```{r}
# convert steps dataset to datetime format
dfhs <- dfhs %>% 
  rename(Datetime = ActivityHour) %>% 
  mutate(Datetime = as.POSIXct(Datetime, format = "%m/%d/%Y %I:%M:%S %p", tz = Sys.timezone())) %>% 
  # separate date and time
  separate(Datetime, into = c("Date", "Time"), sep = " ") 

# convert intensities dataset to datetime format
dfhi <- dfhi %>% 
  rename(Datetime = ActivityHour) %>% 
  mutate(Datetime = as.POSIXct(Datetime, format = "%m/%d/%Y %I:%M:%S %p", tz = Sys.timezone())) %>% 
  # separate date and time
  separate(Datetime, into = c("Date", "Time"), sep = " ")

head(dfhs)
head(dfhi)
```

Combining the activity datasets.
```{r}
# merge hourly steps and intensities datasets
dfh <- merge(dfhs, dfhi, by = c("Id", "Date", "Time"), all.x = TRUE) 

head(dfh)
```

Transforming sleep data (for parsing).
```{r}
# separate date and time
ds2 <- dfs %>% 
  separate(col = SleepDay,into = c("Date", "Time"), sep = " ", remove = TRUE)
head(ds2)
```

The data is now formatted for processing by SQL. 
```{r}
# exporting new csv
# write_csv(ds2, 'Fitbit-Data/daily_sleep.csv')
```

SQL Data Prep Objectives - check for distinct users, merge tables, remove missing values and duplicates, identify mistyped data, adjust columns.

Connecting to BigQuery database.
```{r}
library(bigrquery)
library(DBI)
con <- dbConnect(
  bigrquery::bigquery(),
  project = "fitbit-tracker-analysis",
  dataset = "daily_activity",
)
```

Finding the number of users for each table.
```{sql, connection = con, output.var = "id1"}
# distinct ids for activity table
SELECT COUNT(DISTINCT id) AS users 
FROM `daily_activity`
```
```{sql, connection = con, output.var = "id2"}
# distinct ids for sleep table
SELECT COUNT(DISTINCT id) AS users 
FROM `daily_sleep`
```

Activity data has 33 unique users, and sleep data has 24 unique users. Merging the tables next.
```{sql, connection = con, output.var = "dfn"}
# join activity and sleep data by id and date
CREATE TABLE daily_stats AS
  (SELECT  a.*, s.totalsleeprecords, s.totalminutesasleep
  FROM `daily_activity` a
  LEFT JOIN `daily_sleep` s
  ON a.id = s.id AND a.activitydate = s.date);
```

Now checking for missing/null values.
```{sql, connection = con, output.var = "ntest"}
# check for null values
SELECT * as ntest
FROM `daily_stats`
WHERE calories IS NULL;
```

There are no missing/null values from the activity data. The BigQuery database indicates that the entered data and datatypes are all consistent. Now sorting through the data to check for outliers and mistyped data.

```{sql, connection = con, output.var = "mtest"}
# order columns to check for data errors
SELECT * as mtest
FROM `daily_stats`
ORDER BY calories DESC
```

There are no apparent incorrect data points. Now identifying and removing any duplicates.
```{sql, connection = con, output.var = "dtest"}
# check for duplicates in joined table
SELECT id, activitydate, COUNT(*) AS dtest
FROM `daily_stats`
GROUP BY id, activitydate
HAVING COUNT(*) > 1
```

Adding day of week column to the merged table. Dropping tracker distance, logged activities distance, and sedentary active distance columns (redundant information).
```{sql, connection = con, output.var = "dfn"}
# add day of week to final table
SELECT *, EXTRACT(DAYOFWEEK FROM activitydate) AS day
FROM `daily_stats`;
```
```{sql, connection = con, output.var = "dfn"}
# remove columns
ALTER TABLE `daily_stats`
DROP trackerdistance,
DROP loggedactivitiesdistance,
DROP sedentaryactivedistance;
```

Importing updated dataset.
```{r}
dfn <- read_csv('Fitbit-Data/daily_stats.csv')
head(dfn)
```

Performing final date/time transformations (adding weekday column).
```{r}
# transform daily activity day values to weekdays
dfn$Day[dfn$Day == 1] <- "Sunday"
dfn$Day[dfn$Day == 2] <- "Monday"
dfn$Day[dfn$Day == 3] <- "Tuesday"
dfn$Day[dfn$Day == 4] <- "Wednesday"
dfn$Day[dfn$Day == 5] <- "Thursday"
dfn$Day[dfn$Day == 6] <- "Friday"
dfn$Day[dfn$Day == 7] <- "Saturday"

# add weekday column to hourly activity dataset
dfh <- dfh %>%
  mutate(Day = as.Date(Date)) %>%
  mutate(Day = weekdays(Day))

# clean output
hcols <- c('Id', 'Day', 'Date', 'Time', 'StepTotal', 'TotalIntensity', 'AverageIntensity')
dfh <- dfh[, hcols]

head(dfn)
head(dfh)
```


## ANALYSIS

Initial exploratory analysis will involve understanding general summary statistics of the variables, and user-specific activity data.

```{r}
# summary of daily activity data
summary(dfn)
```

The initial data summaries suggest most users are generally active (median 7439 steps a day). The vast majority of time is spent being sedentary (expected), and the median time spent in intense activity is only 11 minutes (4 very active mins + 7 fairly active minutes). The mean intense activity values are much higher for both (21 very active minutes, 13 fairly active minutes) hinting at a skewed distribution likely due to only a small portion of users having a regular workout routine. Users average around ~7 hours of sleep a night on average. Visualizing these distributions next for clarity.




## DISCUSSION



**Next Steps**





